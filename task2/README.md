## Задание 2. Реализация нейронной сети для детекции объектов CenterNet.

### Описание
В этом задании вам необходимо реализовать на torch упрощенную версию сети CenterNet, статья [Objects as Points](https://arxiv.org/pdf/1904.07850.pdf).
Аналогично первому заданию, имеется пакет-заготовка для реализации сети. Ваша задача - разобраться в статье и реализовать те фрагменты, где в коде встречается
 `raise NotImplementedError` (а также `pass #NotImplemented`).

Замечания:
- изучение кода [оригинальной](https://github.com/xingyizhou/CenterNet) CenterNet приветствуется.
- не перепутайте с другой статьей [CenterNet: Keypoint Triplets for Object Detection](https://arxiv.org/abs/1904.08189): она сложнее!

### Оценка
Оценка ставится инструкторами вручную, с проверкой реализации компонентов и результатов тренировки.
В срок [10.10 – 31.10], `максимум баллов за задание` = 20. Начиная с 31.10, `максимум баллов за задание` = 10. Начиная с 15.12, баллы не ставятся.

### Список компонентов, которые надо реализовать
- abbyy_course_cvdl_t2.backbone.UpscaleTwiceLayer (2 балла)
- abbyy_course_cvdl_t2.backbone.HeadlessResnet34 (2 балла)
- abbyy_course_cvdl_t2.head.CenterNetHead (2 балла)
- abbyy_course_cvdl_t2.loss.CenterNetLoss (2 балла)
- abbyy_course_cvdl_t2.convert.ObjectsToPoints (3 балла)
- abbyy_course_cvdl_t2.convert.PointsToObjects (4 балла)
- abbyy_course_cvdl_t2.network.PointsNonMaxSuppression (3 балла)

Корректность компонентов оценивается по тестам и "на глаз": если компонент не проходит почему-то тест, но по смыслу верен, он будет засчитан
Все компоненты - 18 баллов. Еще 2 балла даются за "успешную" тренировку на TinyCoco( см. ниже ).

### Баллы за тренировку на TinyCoco
Для удобства отладки приложен `task2/checks_notebook.ipynb`, в котором сначала вызываются компоненты по-отдельности, а затем выполняется тренировка на датасете TinyCoco (игрушечная)
Датасет TinyCoco приложен в task2/data, для тренировки на нем достаточно CPU.

Тренировку можно делать с pretrained бэкбоном.

Тренировка считается успешной, если лосс в логах тренировки (выводятся в checks_notebook.ipynb) стабильно понижается.

### Дополнительные баллы за тренировку на CocoText
При тренировке на TinyCoco (~10 изображений) чего-то даже отдаленно работающего не получится в любом случае - слишком мало данных. Чтобы проверить, работоспособен ли написанный вами детектор, его надо обучить на полноразмерном датасете (~10K изображений).

В ноутбуке `train_cocotext.ipynb` приведена тренировка детектора на [CocoText](https://bgshih.github.io/cocotext/) - датасете с изображениями из COCO, на которых размечен весь текст.

Вам необходимо скачать изображения [COCO](https://cocodataset.org) версии 2014 года и разметку cocotext.v2.json с сайта CocoText, прогнать обучение в ноутбуке на своей реализации CenterNet и удостовериться, что ваше детектор после обучения выдаёт что-то похожее на детекции текста.

За успешную тренировку на CocoText дополнительно начисляется 3 балла. У этого пункта дедлайн - конец семестра, т.е. получить доп. баллы за успешную тренировку работающего детектора можно и после 31.10.


## Результаты проверки

1. head.py::CenterNetHead
- Ошибка - в class_heatmap не учтён background класс. В class_heatmap используется `c_classes` каналов с последующим Softmax - значит, что один из c_classes будет обязательно иметь высокую вероятность в каждой локации. Но в подготовке данных (в ObjectsToPoints) в большинстве локаций везде 0 (потому что там нет объектов). Получается, сеть обязана во всех локациях предсказать хоть в одном канале ~1, но в таргете в большинстве локаций везде 0 - лосс будет всегда высоким (и логически неверным). Решается использованием в class_net (c_classes+1) каналов с отбрасыванием 0 или последнего канала (будет соответствовать background). Также можно решить это, использовав сигмоиду вместо softmax - тогда сеть сможет предсказывать везде 0 (так сделано в оригинальной реализации) - правда тогда вероятности несколькх классом могут быть высокими в локации одновременно. Также можно решить проблему, явно учтя в ObjectsToPoints, PointsToObjects и CenterNetLoss одного канала на background (но это более сложны путь)

Вероятно, это и вызывает nan лосс при обучении на tiny_coco:
- в примере используется всего один класс, т.е. c_classses=1
- применяется softmax - единственный канал всегда заполнен 1
- в лоссе вычисляется что-то вроде (1-1)**A * 1**B * log(1 - 1)

2. loss.py::loss_fl
- Замечание - использование циклов очень неэффективно. Более эффективно будет вычислить обе версии (target_cyx[i] == 1, target_cyx[i] != 1) и сложить с int весами (target_cyx[i] == 1).long()
- Замечание - использование проверок для решения проблемы с nan - не самая лучшая идея. Обычно nan возникают из-за какой-то ошибки, в данном случае видимо из-за head.

3. network.py::PointsNonMaxSuppression
-  Ошибка - используются вложенные циклы. В реальности nms на циклах в питоне никогда не реализуется, это слишком неэффективно. Можно посмотреть в авторском коде, как они реализуют nms через max_pool в несколько строк. "The peak keypoint extraction serves as a sufficient NMS alternative and can be implemented efficiently on device using a 3 × 3 max pooling operation" в статье. 

4. convert.py::ObjectsToPoints
-  Ошибка - используются вложенные циклы везде. Циклы по батчам еще ладно, и в .compute_objects_locations не совсем тривиальная реализация. Но в compute_objects_sizes из [B, N, 6] извлечь h,w в [B*N] - достаточно индексации и flatten в одну строчку. Python-циклы с поэлементным доступом к тензорам на GPU - это очень неэффективно, сеть будет заметно дольше учиться.
- Замечание - в smooth_points_heatmap используется цикл по каналам. Вместо этого можно было бы использовать групповую(channelwise) свёртку (параметр каналов Conv2D `groups=points_heatmap.shape[1]`) с ядром smooth_kernel

Итого:
- "замечания" не влияют на баллы
- в тренировке на TinyCoco лосс падает, но по факту там ошибка - L1+ FL лосс вообще должен быть неотрицательным (причина видимо в head.py); -1 балл
- в head.py ошибка: -1 балл
- в NMS используются циклы, но он (видимо) работает: -1 балл
- в ObjectsToPoints используются циклы в тривиальных случаях: -1 балл


16 баллов
